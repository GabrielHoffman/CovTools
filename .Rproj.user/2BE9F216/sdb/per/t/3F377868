{
    "collab_server" : "",
    "contents" : "#' Covariance Estimation via Adaptive Thresholding\n#'\n#' Cai and Liu (2011) proposed an adaptive variant of Bickel and Levina (2008) - \\code{\\link{CovEst.Bickel08}}. The idea of \\emph{adaptive thresholding} is\n#' to apply thresholding technique on correlation matrix in that it becomes \\emph{adaptive} in terms of each variable.\n#'\n#' @param X an \\eqn{(n\\times p)} matrix where each row is an observation.\n#' @param thr user-defined threshold value. If it is a vector of regularization values, it automatically selects one that minimizes cross validation risk.\n#' @param nCV the number of repetitions for 2-fold random cross validations for each threshold value.\n#' @param parallel a logical; \\code{TRUE} to use half of available cores, \\code{FALSE} to do every computation sequentially.\n#'\n#' @return a named list containing: \\describe{\n#' \\item{S}{a \\eqn{(p\\times p)} covariance matrix estimate.}\n#' \\item{CV}{a dataframe containing vector of tested threshold values(\\code{thr}) and corresponding cross validation scores(\\code{CVscore}).}\n#' }\n#'\n#' @examples\n#' ## generate data from multivariate normal with Identity covariance.\n#' data <- mvtnorm::rmvnorm(100, sigma=diag(5))\n#'\n#' ## apply 4 different schemes\n#' #  mthr is a vector of regularization parameters to be tested\n#' mthr <- seq(from=0.01,to=0.99,length.out=10)\n#'\n#' out1 <- CovEst.Cai11(data, thr=0.1)  # threshold value 0.1\n#' out2 <- CovEst.Cai11(data, thr=0.5)  # threshold value 0.5\n#' out3 <- CovEst.Cai11(data, thr=0.5)  # threshold value 0.9\n#' out4 <- CovEst.Cai11(data, thr=mthr) # automatic threshold checking\n#'\n#' ## visualize 4 estimated matrices\n#' par(mfrow=c(2,2), pty=\"s\")\n#' image(pracma::flipud(out1$S), col=gray((0:100)/100), main=\"thr=0.1\")\n#' image(pracma::flipud(out2$S), col=gray((0:100)/100), main=\"thr=0.5\")\n#' image(pracma::flipud(out3$S), col=gray((0:100)/100), main=\"thr=0.9\")\n#' image(pracma::flipud(out4$S), col=gray((0:100)/100), main=\"automatic\")\n#'\n#' @references\n#' \\insertRef{cai_adaptive_2011}{CovTools}\n#'\n#' @rdname CovEst_Cai11\n#' @export\nCovEst.Cai11 <- function(X, thr=0.5, nCV=10, parallel=TRUE){\n  #-----------------------------------------------------\n  ## PREPROCESSING\n  fname    = \"Cai11\"\n  pnameTHR = \"'thr'\"\n  pnamenCV = \"'nCV\"\n  pnamenthrs = \"'nthrs'\"\n  #   1. data matrix\n  checker1 = invisible_datamatrix(X, fname)\n  #   2. thr\n  if (length(as.vector(thr))==1){\n    checker3 = invisible_PosReal(thr, fname, pnameTHR)\n    CV = FALSE\n  } else { # vector threshold value case\n    nthrs = length(thr)\n    for (i in 1:nthrs){\n      checker3 = invisible_PosReal(thr[i], fname, pnameTHR)\n    }\n    CV = TRUE\n  }\n  #   4. nCV\n  checker4 = invisible_PosIntMM(nCV, fname, pnamenCV, 1, nrow(X))\n  #   5. parallel\n  if (!parallel){\n    nCore = 1\n  } else {\n    nCore = max(round(detectCores()/2),1)\n  }\n\n  #-----------------------------------------------------\n  ## MAIN COMPUTATION\n  if (CV==FALSE){\n    output = covest.Cai11.once(X,thr)\n  } else {\n    output = covest.Bickel08(X,nCV,nCore,thr)\n  }\n\n  #-----------------------------------------------------\n  ## RETURN OUTPUT\n  return(output)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#  ------------------------------------------------------------------------\n#  Auxiliary Functions for CovEst.Cai11\n#  ------------------------------------------------------------------------\n# [Cai11] Adaptive Thresholding for Sparse CovMatEst ----------------------\n#' @keywords internal\n#' @noRd\ncovest.Cai11.once <- function(X,thrlevel){\n  C = cor(X)\n  C[which(abs(C)<=thrlevel)] = 0\n  diag(C) = diag(cor(X))\n  S = cov(X)\n  dS2 = diag(sqrt(diag(S)))\n  output = dS2 %*% C %*% dS2\n\n  outputs = list()\n  outputs$S = output\n  # return outputs\n  return(outputs)\n}\n#' @keywords internal\n#' @noRd\ncovest.Cai11 <- function(X,nCV,nCore,thrvec){\n  # get parameters\n  n = nrow(X); p=ncol(X);\n  nsearch = length(thrvec);\n  # nCV\n  S1 = array(0,c(p,p,nCV))\n  S2 = array(0,c(p,p,nCV))\n  nselect = round(n*(1-(1/log(n))))\n  # divide and compute S for nfold cross validation\n  idxall = (1:n)\n  for (i in 1:nCV){\n    idx1 = sample(idxall, nselect)\n    idx2 = setdiff(idxall, idx1)\n    S1[,,i] = cor(X[idx1,])\n    S2[,,i] = cor(X[idx2,])\n  }\n  # total of 100 threshold values will be tested.\n  stest  = sort(thrvec, decreasing=FALSE)\n  # parallel setup\n  if (nCore==1){\n    cl = makeCluster(1)\n    registerDoParallel(cl)\n  } else {\n    cl = makeCluster(nCore)\n    registerDoParallel(cl)\n  }\n  # parallel computation let's go\n  # at first, let's not use\n  itforeach=NULL\n  Rs = foreach (itforeach=1:nsearch, .combine=cbind) %dopar% {\n    covest.Bickel08.singlesum(S1,S2,stest[itforeach])\n  }\n  # stop cluster\n  stopCluster(cl)\n  # find the minimal element.\n  idxsmin = which(Rs==min(Rs))\n  if (length(idxsmin)>1){\n    idxsmin = idxsmin[1]\n  }\n  # optimal threshold value\n  thropt = stest[idxsmin]\n  # Compute Sample Covariance anyway\n  C = cor(X)\n  C[which(abs(C)<=thropt)] = 0\n  diag(C) = diag(cor(X))\n  S = cov(X)\n  dS2 = diag(sqrt(diag(S)))\n  output = dS2 %*% C %*% dS2\n\n\n  outputs = list()\n  outputs$S = output\n  outputs$CV = data.frame(thr=stest, CVscore=as.vector(Rs))\n  # return outputs\n  return(outputs)\n}\n\n",
    "created" : 1513118868133.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1996159083",
    "id" : "3F377868",
    "lastKnownWriteTime" : 1513120282,
    "last_content_update" : 1513120282148,
    "path" : "~/Desktop/CovTools/R/CovEst.Cai11.R",
    "project_path" : "R/CovEst.Cai11.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}