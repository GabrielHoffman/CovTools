{
    "collab_server" : "",
    "contents" : "\n\n\n# [Donoho95] Wavelet Shrinkage: Asymptopia? -------------------------------\n#' @keywords internal\n#' @noRd\ncovest.Donoho95.once <- function(X,thrlevel){\n  # Apply Soft Thresholding\n  S    = cov(X)\n  outS = covest.Donoho95.applysoft(S, thrlevel)\n  output = list()\n  output$S = outS\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Donoho95 <- function(X,nCV,nCore,nsearch){\n  # get parameters\n  n = nrow(X); p=ncol(X);\n  # nCV\n  S1 = array(0,c(p,p,nCV))\n  S2 = array(0,c(p,p,nCV))\n  nselect = round(n*(1-(1/log(n))))\n  # divide and compute S for nfold cross validation\n  idxall = (1:n)\n  for (i in 1:nCV){\n    idx1 = sample(idxall, nselect)\n    idx2 = setdiff(idxall, idx1)\n    S1[,,i] = cov(X[idx1,])\n    S2[,,i] = cov(X[idx2,])\n  }\n  # total of 100 threshold values will be tested.\n  S = cov(X)\n  stest  = seq(from=(0.01*max(abs(S))),to=(0.99*max(abs(S))),length.out=nsearch)\n  # parallel setup\n  if (nCore==1){\n    cl = makeCluster(1)\n    registerDoParallel(cl)\n  } else {\n    cl = makeCluster(nCore)\n    registerDoParallel(cl)\n  }\n  # parallel computation let's go\n  # at first, let's not use\n  itforeach=NULL\n  Rs = foreach (itforeach=1:nsearch, .combine=cbind) %dopar% {\n    covest.Donoho95.singlesum(S1,S2,stest[itforeach])\n  }\n  # stop cluster\n  stopCluster(cl)\n  # find the minimal element.\n  idxsmin = which(Rs==min(Rs))\n  if (length(idxsmin)>1){\n    idxsmin = idxsmin[1]\n  }\n  # optimal threshold value\n  thropt = stest[idxsmin]\n  # Apply Soft Thresholding\n  outS = covest.Donoho95.applysoft(S, thropt)\n  output = list()\n  output$S = outS\n  output$CV = data.frame(thr=stest, CVscore=as.vector(Rs))\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Donoho95.singlesum <- function(S1, S2, thr){\n  N = dim(S1)[3]\n  output = 0\n  for (i in 1:N){\n    S1tmp = covest.Donoho95.applysoft(S1[,,i], thr)\n    S2tmp = S2[,,i]\n    output= output + norm(S1tmp-S2tmp, \"f\")\n  }\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Donoho95.applysoft <- function(S, thr){\n  output = array(0,dim(S))\n  idxPos = which(S>0)\n  idxNeg = which(S<0)\n\n  # positive part\n  output[idxPos] = pmax(S[idxPos]-thr,0)\n  output[idxNeg] = pmin(0,S[idxNeg]+thr)\n  diag(output)   = diag(S)\n  return(output)\n}\n\n\n# [Fan.2013] Large covariance estimation by thresholding pc ---------------\n#' @keywords internal\n#' @noRd\ncovest.Fan13.once <- function(X,thropt){\n  S    = cov(X)\n  outS = covest.Fan13.singlethr(S, thropt)\n  output = list()\n  output$S = outS\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Fan13 <- function(X,nCV,nCore,nsearch){\n  # get parameters\n  n = nrow(X); p=ncol(X);\n  # nCV\n  S1 = array(0,c(p,p,nCV))\n  S2 = array(0,c(p,p,nCV))\n  nselect = round(n*(1-(1/log(n))))\n  # divide and compute S for nfold cross validation\n  idxall = (1:n)\n  for (i in 1:nCV){\n    idx1 = sample(idxall, nselect)\n    idx2 = setdiff(idxall, idx1)\n    S1[,,i] = cov(X[idx1,])\n    S2[,,i] = cov(X[idx2,])\n  }\n\n  ## 1st. we need to find Cmin\n  covX   = cov(X)\n  SS     = covX\n  Cflag  = TRUE\n  Cmax = max(abs(setdiff(as.vector(SS),diag(covX))))\n  Cmin = Cmax\n  for (i in 1:1000){\n    Cmin   = 0.99*Cmin  #update Cmax\n    SS     = covest.Fan13.singlethr(SS, Cmin)\n    eigSS  = min(eigen(SS, only.values = TRUE)$values)\n    if (eigSS<=sqrt(sqrt(.Machine$double.eps))){\n      Cmin = Cmin/0.99\n      break\n    }\n  }\n  if (Cmin==Cmax){\n    message(\"* CovEst.Fan13 : Cmin is identical to Cmax.\")\n    Cmin = 0.9999*Cmax\n  }\n\n  ## 2nd. now, crossvalidation is run.\n  stest  = seq(from=Cmin, to=Cmax, length.out=nsearch)\n  # parallel setup\n  if (nCore==1){\n    cl = makeCluster(1)\n    registerDoParallel(cl)\n  } else {\n    cl = makeCluster(nCore)\n    registerDoParallel(cl)\n  }\n  # parallel computation let's go\n  # at first, let's not use\n  itforeach=NULL\n  Rs = foreach (itforeach=1:nsearch, .combine=cbind) %dopar% {\n    covest.Bickel08.singlesum(S1,S2,stest[itforeach])\n  }\n  # stop cluster\n  stopCluster(cl)\n  # find the minimal element.\n  idxsmin = which(Rs==min(Rs))\n  if (length(idxsmin)>1){\n    idxsmin = idxsmin[1]\n  }\n  # optimal threshold value\n  thropt = stest[idxsmin]\n  # Apply Hard Thresholding\n  S    = cov(X)\n  outS = covest.Fan13.singlethr(S, thropt)\n  output = list()\n  output$S = outS\n  output$CV = data.frame(thr=stest, CVscore=as.vector(Rs))\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Fan13.singlethr <- function(SS, thr){\n  S = SS\n  S[which(abs(S)<=thr)] = 0\n  diag(S) = diag(SS)\n  return(S)\n}\n\n\n# [Qi.2006] nearPD --------------------------------------------------------\n#' @keywords internal\n#' @noRd\ncovest.Qi06.once <- function(X){\n  diagShalf = diag(sqrt(diag(cov(X))))\n  Rt        = cor(X)\n  Rhat      = matrix(Matrix::nearPD(Rt,corr=TRUE,keepDiag=TRUE)$mat, nrow=nrow(Rt))\n  Shat      = diagShalf%*%Rhat%*%diagShalf\n\n  output    = list()\n  output$S  = Shat\n  return(output)\n}\n#' @keywords internal\n#' @noRd\ncovest.Qi06 <- function(X){\n  diagShalf = diag(sqrt(diag(cov(X))))\n  Rt        = cor(X)\n  Rhat      = matrix(Matrix::nearPD(Rt,corr=TRUE,keepDiag=TRUE)$mat, nrow=nrow(Rt))\n  Shat      = diagShalf%*%Rhat%*%diagShalf\n\n  output    = list()\n  output$S  = Shat\n  output$CV = \"* CovEst : nearest correlation matrix method does not involve cross validation.\"\n  return(output)\n}\n\n",
    "created" : 1513117950809.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3388129675",
    "id" : "B6A522A8",
    "lastKnownWriteTime" : 1513119461,
    "last_content_update" : 1513119461447,
    "path" : "~/Desktop/CovTools/R/fns.covest.R",
    "project_path" : "R/fns.covest.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}