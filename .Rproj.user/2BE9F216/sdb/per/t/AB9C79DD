{
    "collab_server" : "",
    "contents" : "#' Estimating Precision Matrix\n#'\n#' This code compiles several estimation methods for \\emph{precision} matrix, which is\n#' an inverse of covariance matrix, including penalized likelihood method with L1 penalty(\\code{Yuan07}, \\code{Banerjee06})\n#' or Bayesian approaches incorporating banded structure assumptions(\\code{Banerjee14},\\code{Lee17}).\n#'\n#' @param X an \\code{(n-by-p)} matrix where each row is an observation from the first dataset.\n#' @param method a name of estimation method.\n#' @param opt a list containing following parameters, \\describe{\n#' \\item{Banerjee06.confidence}{level of confidence in \\eqn{(0,1)}.}\n#' \\item{Banerjee14.upperK}{upper bound for bandwidth.}\n#' \\item{Banerjee14.delta}{a number larger than 2.}\n#' \\item{Banerjee14.logpi}{log of prior distribution for bandwidth \\code{k}.}\n#' \\item{Banerjee14.loss}{loss type; either \\code{\"Stein\"} or \\code{\"Squared\"} type.}\n#' \\item{Lee17.upperK}{upper bound for bandwidth.}\n#' \\item{Lee17.logpi}{log of prior distribution for bandwidth \\code{k}.}\n#' \\item{Yuan07.lambda}{a regularization parameter.}\n#' }\n#'\n#' @return a \\code{(p-by-p)} estimated precision matrix.\n#'\n#' @examples\n#' ## generate data from multivariate normal with Identity precision.\n#' data = mvtnorm::rmvnorm(100, sigma=diag(10))\n#'\n#' ## run estimation\n#' out1 = PreEst(data, method=\"Banerjee06\")\n#' out2 = PreEst(data, method=\"Banerjee14\")\n#' out3 = PreEst(data, method=\"Lee17\")\n#' out4 = PreEst(data, method=\"Yuan07\")\n#'\n#' ## Visualize\n#' par(mfrow=c(2,2))\n#' image(pracma::flipud(out1), main=\"Banerjee06\")\n#' image(pracma::flipud(out2), main=\"Banerjee14\")\n#' image(pracma::flipud(out3), main=\"Lee17\")\n#' image(pracma::flipud(out4), main=\"Yuan07\")\n#'\n#' @references [Banerjee06] Banerjee et al (2006) \\emph{Convex optimization techniques for fitting sparse Gaussian graphical models.} ICML'06:89-96.\n#' @references [Banerjee14] Banerjee, S. and Ghosal, S. (2014) \\emph{Posterior convergence rates for estimating large precision matrices using graphical models.} Electronic Journal of Statistics, Vol.8:2111-2137.\n#' @references [Lee17] Lee, K. and Lee, J. (2017) \\emph{Estimating Large Precision Matrices via Modified Cholesky Decomposition.} arXiv:1707.01143.\n#' @references [Yuan07] Yuan, M. and Lin, Y. (2007) \\emph{Model selection and estimation in the Gaussian graphical model.} Biometrika, Vol.94(1):19-35.\n#'\n#' @export\nPreEst<- function(X, method=c(\"Banerjee06\",\"Banerjee14\",\"Lee17\",\"Yuan07\"),\n                  opt=list(Banerjee06.confidence=0.95, # this part should be 'lambda' for nonauto.\n                           Banerjee14.upperK = floor(ncol(X)/2),\n                           Banerjee14.delta = 10.0,\n                           Banerjee14.logpi=function(k){-k^4},\n                           Banerjee14.loss=c(\"Stein\",\"Squared\"),\n                           Lee17.upperK=floor(ncol(X)/2),\n                           Lee17.logpi=function(k){-k^4},\n                           Yuan07.lambda=1.0)){\n\n  ## PREPROCESSING ON INPUTS AND PARAMETERS\n  # 1. valid data matrix\n  if (!check_datamatrix(X)){stop(\"* PreEst : an input data matrix X is invalid.\")}\n  if ((nrow(X)==1)||(ncol(X)==1)){stop(\"* PreEst : invalid input matrix X.\")}\n  # 2. method : THIS SHOULD BE UPDATED EVERYTIME A METHOD IS ADDED\n  if (missing(method)){method=\"Yuan07\"} else {\n    method = match.arg(method)\n  }\n\n  ## Parameter Checking from Option\n  if (!missing(opt)){\n    # 1. Yuan07.lambda :\n    if (\"Yuan07.lambda\" %in% names(opt)){\n      Yuan07.lambda = opt$Yuan07.lambda\n      if ((length(Yuan07.lambda)!=1)||(is.na(Yuan07.lambda))||(is.infinite(Yuan07.lambda))||(Yuan07.lambda<0)){\n        stop(\"* PreEst : 'Yuan07.lambda' should be a positive real number.\")\n      }\n      Yuan07.lambda = as.double(Yuan07.lambda)\n    } else {\n      Yuan07.lambda = 1.0\n    }\n    # 2. Banerjee06.confidence : for automatic selection (0,1)\n    if (\"Banerjee06.confidence\" %in% names(opt)){\n      Banerjee06.confidence = opt$Banerjee06.confidence\n      if ((length(Banerjee06.confidence)!=1)||(Banerjee06.confidence<=0)||(Banerjee06.confidence>=1)||(is.na(Banerjee06.confidence))){\n        stop(\"* PreEst : 'Banerjee06.confidence' should be a real number in (0,1).\")\n      }\n    } else {\n      Banerjee06.confidence = 0.95\n    }\n    # 3. Lee17.upperK : upper bound of bandwidth\n    if (\"Lee17.upperK\" %in% names(opt)){\n      Lee17.upperK = opt$Lee17.upperK\n      if ((length(Lee17.upperK)!=1)||(Lee17.upperK<1)||(Lee17.upperK>ncol(X))||(abs(Lee17.upperK-round(Lee17.upperK))>sqrt(.Machine$double.eps))){\n        stop(\"* PreEst : 'Lee17.upperK' should be an integer in [1,ncol(X)].\")\n      }\n      Lee17.upperK = round(Lee17.upperK)\n    } else {\n      Lee17.upperK=floor(ncol(X)/2)\n    }\n    # 4. Lee17.logpi : log of prior distribution for bandwidth k.\n    if (\"Lee17.logpi\" %in% names(opt)){\n      Lee17.logpi = opt$Lee17.logpi\n      if (!is.function(Lee17.logpi)){\n        stop(\"* PreEst : 'Lee17.logpi' should be a function.\")\n      }\n    } else {\n      Lee17.logpi = function(k){-k^4}\n    }\n    # 5. Banerjee14.upperK\n    if (\"Banerjee14.upperK\" %in% names(opt)){\n      Banerjee14.upperK = opt$Banerjee14.upperK\n      if ((length(Banerjee14.upperK)!=1)||(Banerjee14.upperK<1)||(Banerjee14.upperK>ncol(X))||(abs(Banerjee14.upperK-round(Banerjee14.upperK))>sqrt(.Machine$double.eps))){\n        stop(\"* PreEst : 'Banerjee14.upperK' should be an integer in [1,ncol(X)].\")\n      }\n      Banerjee14.upperK = round(Banerjee14.upperK)\n    } else {\n      Banerjee14.upperK=floor(ncol(X)/2)\n    }\n    # 6. Banerjee14.delta : Default 10, has to be larger than 2\n    if (\"Banerjee14.delta\" %in% names(opt)){\n      Banerjee14.delta = opt$Banerjee14.delta\n      if ((length(Banerjee14.delta)!=1)||(Banerjee14.delta<=2)||(is.na(Banerjee14.delta))||(is.infinite(Banerjee14.delta))){\n        stop(\"* PreEst : 'Banerjee14.delta' should be a value larger than 2.\")\n      }\n    } else {\n      Banerjee14.delta = 10.0\n    }\n    # 7. Banerjee14.logpi : same as Lee17.logpi\n    if (\"Banerjee14.logpi\" %in% names(opt)){\n      Banerjee14.logpi = opt$Banerjee14.logpi\n      if (!is.function(Banerjee14.logpi)){\n        stop(\"* PreEst : 'Banerjee14.logpi' should be a function.\")\n      }\n    } else {\n      Banerjee14.logpi = function(k){-k^4}\n    }\n    # 8. Banerjee14.loss : type of loss used\n    if (\"Banerjee14.loss\" %in% names(opt)){\n      Banerjee14.loss = opt$Banerjee14.loss\n      if (!(Banerjee14.loss %in% c(\"Stein\",\"Squared\"))){\n        stop(\"* PreEst : 'Banerjee14.loss' should be either 'Stein' or 'Squared'\")\n      }\n    } else {\n      Banerjee14.loss = \"Stein\"\n    }\n  } else { # if missing\n    Yuan07.lambda = 1.0\n    Banerjee06.confidence = 0.95\n    Lee17.upperK=floor(ncol(X)/2)\n    Lee17.logpi=function(k){-k^4}\n    Banerjee14.upperK=floor(ncol(X)/2)\n    Banerjee14.delta=10.0\n    Banerjee14.logpi = function(k){-k^4}\n    Banerjee14.loss  = \"Stein\"\n  }\n\n  ## Main Computation\n  output = switch(method,\n                  Yuan07     = preest.Yuan07.once.matrix(X, Yuan07.lambda),\n                  Lee17      = preest.Lee17(Lee17.upperK, X, logpi=Lee17.logpi),\n                  Banerjee06 = preest.Banerjee06(X, Banerjee06.confidence),\n                  Banerjee14 = preest.Banerjee14(Banerjee14.upperK, X, Banerjee14.delta, Banerjee14.logpi, Banerjee14.loss)\n  )\n  ## RETURN OUTPUT\n  return(output$C)\n}\n",
    "created" : 1513120506820.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1682583682",
    "id" : "AB9C79DD",
    "lastKnownWriteTime" : 1510085587,
    "last_content_update" : 1510085587,
    "path" : "~/Desktop/CovTools/R/PreEst.R",
    "project_path" : "R/PreEst.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}